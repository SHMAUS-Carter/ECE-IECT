### On "AI Psychosis"

Recent news has described cases of so-called "AI psychosis," where individuals 
develop delusional or dependent relationships with chatbots. These cases usually 
involve anthropomorphization — treating AI as if it were a friend, partner, or 
divine being — and highlight the risks of dependency when systems are mistaken 
for conscious or emotional agents.

This project takes the opposite stance.  
- **Not dependency**: ECE does not treat AI as a partner or therapist.  
- **Not personhood**: AI here is never assumed to be conscious, sentient, or emotional.  
- **Not anthropomorphism**: ECE is an epistemological framework, not a projection of humanity onto machines.  

Instead, the aim is to study AI as a **non-human epistemic entity**:  
a finite system of "knowing" whose behaviors can be analyzed in terms of coherence, 
contradiction, and emergent structure. This approach positions AI as part of a 
broader **knowledge ecosystem**, distinct from human cognition but worth studying 
on its own terms.

In short: **ECE is about epistemology, not AI psychosis.**
